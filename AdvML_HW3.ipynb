{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Takuro Sazaki\n",
        "## UNI: ts3422\n",
        "## Github repo: https://github.com/tzak16/QMSS-G5074.git"
      ],
      "metadata": {
        "id": "5I0fkPTG1AUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "\n",
        "Your final report should be written up in a Jupyter notebook.  It should be posted to a public Github repo as an ipynb  submitted to this assignment via courseworks.  Please include the link to your Github repo in this ipynb file.\n",
        "\n",
        "Use the deep learning and sklearn example ipynb notebooks from the Week 11 folder for example submission code.\n",
        "\n",
        "Note: After installing aimodelshare in Colab you may need use dropdown menus to restart yours session before running code.  Use Runtime > restart runtime to restart your Colab session.\n",
        "\n",
        "Your report should include the following information:"
      ],
      "metadata": {
        "id": "v3qtD0rTyI93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "NFN0ZttQKOJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare==0.0.189"
      ],
      "metadata": {
        "id": "OkqfM5wC0QFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install protobuf==3.19.6"
      ],
      "metadata": {
        "id": "zOsdFKn-EL4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get competition data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikfa8xIs89iJ",
        "outputId": "3c1f89ae-1c67-4407-c5d4-23c2cda2b5b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [=============================================>   ]\n",
            "\n",
            "Data downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up X_train, X_test, and y_train_labels objects\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
        "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
        "\n",
        "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
        "\n",
        "# ohe encode Y data\n",
        "y_train = pd.get_dummies(y_train_labels)\n",
        "\n",
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZU_Xq_i9IfJ",
        "outputId": "aa9a8213-b3e9-4748-d5f3-45714976798e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The Rock is destined to be the 21st Century 's...\n",
              "1    The gorgeously elaborate continuation of `` Th...\n",
              "2    Singer/composer Bryan Adams contributes a slew...\n",
              "3                 Yet the act is still charming here .\n",
              "4    Whether or not you 're enlightened by any of D...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=40, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgIVgeoxFU9Q",
        "outputId": "cefa550e-ee2d-4709-8bdc-fee629ec069e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 40)\n",
            "(1821, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain."
      ],
      "metadata": {
        "id": "x5R0SA6pzIC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "he dataset comprises 50,000 movie reviews, which are divided into training and testing sets and labeled with a binary sentiment classification - either \"positive\" or \"negative\". <br/>Developing a predictive model using this data can be highly beneficial as it enables us to classify the sentiment of movie reviews without requiring human intervention. This can be particularly useful for film production companies that seek to analyze and aggregate movie reviews."
      ],
      "metadata": {
        "id": "Tud7tXv0GBQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run at least three prediction models to try to predict the SST sentiment dataset well. "
      ],
      "metadata": {
        "id": "e0ZSAMdOzf69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use an Embedding layer and LSTM layers in at least one model"
      ],
      "metadata": {
        "id": "UVilYidPzlIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(10000, 16, input_length=40))\n",
        "model1.add(LSTM(32, return_sequences=True))\n",
        "model1.add(LSTM(32, return_sequences=True))\n",
        "model1.add(LSTM(32, return_sequences=True))\n",
        "model1.add(LSTM(32))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model1.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao6x5MOZ0I92",
        "outputId": "f9b8c29b-589d-4b72-cc26-4223ca75dd91"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 22s 86ms/step - loss: 0.6484 - acc: 0.6306 - val_loss: 0.7971 - val_acc: 0.4299\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 14s 81ms/step - loss: 0.4802 - acc: 0.7720 - val_loss: 0.7037 - val_acc: 0.6611\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 13s 75ms/step - loss: 0.3578 - acc: 0.8483 - val_loss: 0.8124 - val_acc: 0.5571\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 11s 66ms/step - loss: 0.2859 - acc: 0.8853 - val_loss: 0.5272 - val_acc: 0.7536\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 14s 81ms/step - loss: 0.2259 - acc: 0.9093 - val_loss: 0.7685 - val_acc: 0.6568\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 13s 74ms/step - loss: 0.1873 - acc: 0.9245 - val_loss: 0.7220 - val_acc: 0.7276\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 12s 68ms/step - loss: 0.1611 - acc: 0.9330 - val_loss: 0.7544 - val_acc: 0.7413\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 14s 80ms/step - loss: 0.1387 - acc: 0.9469 - val_loss: 0.5110 - val_acc: 0.7948\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 12s 70ms/step - loss: 0.1201 - acc: 0.9559 - val_loss: 0.7455 - val_acc: 0.7536\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 12s 72ms/step - loss: 0.1076 - acc: 0.9606 - val_loss: 0.7286 - val_acc: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMb2qnk0KixG",
        "outputId": "b8202297-9d19-40c6-8881-1cf69689bd5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model1 = model_to_onnx(model1, framework='keras',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model1.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model1.SerializeToString())"
      ],
      "metadata": {
        "id": "I1BjzCpJKiu_"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this Movie Review Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU0vbWsYKis9",
        "outputId": "426c067a-4107-45b6-8da8-09c6046f43b0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate Competition\n",
        "import aimodelshare as ai\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "metadata": {
        "id": "SAfslAaWKXTy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 1: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 1)\n",
        "prediction_column_index = model1.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model1.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 custom_metadata = {\"team\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5QYsrtNKXRb",
        "outputId": "4c1e1d98-5afd-436e-af4d-cae2a581d746"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 3s 20ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 272\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "hT3vtELdKXOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use an Embedding layer and Conv1d layers in at least one model"
      ],
      "metadata": {
        "id": "_m8d0-QmzlGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(10000, 16, input_length=40))\n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.MaxPooling1D(3))\n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.GlobalAveragePooling1D())\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHLGoMjb0JoT",
        "outputId": "3e79429d-e73b-48c3-8f79-50908c17cb2a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_38 (Embedding)    (None, 40, 16)            160000    \n",
            "                                                                 \n",
            " conv1d_109 (Conv1D)         (None, 38, 32)            1568      \n",
            "                                                                 \n",
            " conv1d_110 (Conv1D)         (None, 36, 32)            3104      \n",
            "                                                                 \n",
            " max_pooling1d_30 (MaxPoolin  (None, 12, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_111 (Conv1D)         (None, 10, 32)            3104      \n",
            "                                                                 \n",
            " conv1d_112 (Conv1D)         (None, 8, 32)             3104      \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 32)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 170,946\n",
            "Trainable params: 170,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model2.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgATaae7Kz7A",
        "outputId": "39ce9df9-fc02-4fb2-d8fe-bba9bcce867e"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 3s 9ms/step - loss: 0.6648 - acc: 0.6134 - val_loss: 0.9901 - val_acc: 0.1488\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.5598 - acc: 0.6954 - val_loss: 0.7181 - val_acc: 0.6142\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.4034 - acc: 0.8228 - val_loss: 0.4946 - val_acc: 0.7796\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.3148 - acc: 0.8701 - val_loss: 0.5110 - val_acc: 0.7695\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.2561 - acc: 0.8951 - val_loss: 0.6079 - val_acc: 0.7572\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.2088 - acc: 0.9164 - val_loss: 0.6767 - val_acc: 0.7421\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 2s 13ms/step - loss: 0.1742 - acc: 0.9301 - val_loss: 0.6950 - val_acc: 0.7616\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 2s 13ms/step - loss: 0.1473 - acc: 0.9417 - val_loss: 0.8574 - val_acc: 0.7189\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 2s 13ms/step - loss: 0.1190 - acc: 0.9561 - val_loss: 0.5157 - val_acc: 0.8223\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 2s 13ms/step - loss: 0.1000 - acc: 0.9632 - val_loss: 1.4222 - val_acc: 0.6452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model2 = model_to_onnx(model2, framework='keras',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model2.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model2.SerializeToString())"
      ],
      "metadata": {
        "id": "zW9qHTS8KzxI"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 2: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 1)\n",
        "prediction_column_index = model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model2.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 custom_metadata = {\"team\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1DIMnHAKzux",
        "outputId": "012266bf-483b-4e1e-f64c-73786da5ea44"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 4ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 273\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "0rbbtrNMKzsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use transfer learning with glove embeddings for at least one of these models"
      ],
      "metadata": {
        "id": "HnjTVNOjzlAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What if we wanted to use a matrix of pretrained embeddings?  Same as transfer learning before, but now we are importing a pretrained Embedding matrix:\n",
        "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
        "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b01-CQwbmG3P",
        "outputId": "e707fe15-d146-4c6a-b8b1-6e464e2609ff"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-17 00:23:56--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-17 00:23:56--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-17 00:23:56--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.05MB/s    in 2m 40s  \n",
            "\n",
            "2023-04-17 00:26:37 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip glove.6B.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93oivN4mNW3",
        "outputId": "87166791-468d-4925-8137-1d83eb02bbec"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embedding data for 100 feature embedding matrix\n",
        "import os\n",
        "glove_dir = os.getcwd()\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBYBu6tzmPyE",
        "outputId": "fda2150d-ed94-4a8a-b475-caaf1a7a8ad2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400001 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "ytRIDseLoDzC"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build embedding matrix\n",
        "embedding_dim = 100 # change if you use txt files using larger number of features\n",
        "maxlen = 40  # We will cut reviews after 100 words in sequence\n",
        "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "U8vA9I9YmSvz"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.MaxPooling1D(3))\n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.Conv1D(32, 3, activation='relu')) \n",
        "model2.add(layers.GlobalMaxPooling1D())\n",
        "model2.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "_t5E1c3ZNyV5"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.layers[0].set_weights([embedding_matrix])\n",
        "model2.layers[0].trainable = False\n",
        "\n",
        "model2.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model2.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n",
        "model2.save_weights('pre_trained_glove_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwn1k9OpLFfS",
        "outputId": "f20ae80f-cf58-4ee2-a968-68cd6a115af2"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 3s 10ms/step - loss: 0.6223 - acc: 0.6434 - val_loss: 0.6924 - val_acc: 0.6236\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.5406 - acc: 0.7227 - val_loss: 0.6035 - val_acc: 0.7168\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.4968 - acc: 0.7542 - val_loss: 0.5931 - val_acc: 0.7182\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.4688 - acc: 0.7726 - val_loss: 0.5515 - val_acc: 0.7478\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.4413 - acc: 0.7870 - val_loss: 0.7053 - val_acc: 0.6416\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 3s 15ms/step - loss: 0.4088 - acc: 0.8083 - val_loss: 0.5969 - val_acc: 0.7103\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 3s 15ms/step - loss: 0.3778 - acc: 0.8273 - val_loss: 0.7637 - val_acc: 0.6380\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 3s 15ms/step - loss: 0.3463 - acc: 0.8454 - val_loss: 0.8898 - val_acc: 0.5838\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.3142 - acc: 0.8618 - val_loss: 0.9964 - val_acc: 0.5932\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.2857 - acc: 0.8837 - val_loss: 0.6180 - val_acc: 0.7283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model3 = model_to_onnx(model2, framework='keras',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=True,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model3.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model3.SerializeToString())"
      ],
      "metadata": {
        "id": "PP8cF4TqK-W-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 3: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 1)\n",
        "prediction_column_index = model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 3 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model3.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 custom_metadata = {\"team\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE5pUeXxK-UH",
        "outputId": "116fa285-87e6-43ce-8732-1984dc2595b5"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 3ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 274\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "lBg71-V-K-RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discuss which models performed better and point out relevant hyper-parameter values for successful models."
      ],
      "metadata": {
        "id": "or4c9dXwzk5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning model with four LSTM layers performed the best among three models I tried. I put the units of 32 for all of the four LSTM layers.\n",
        "<br/> Transfer learning improved the performance of Conv1D model, but the performance did not exceed that of the LSTM model."
      ],
      "metadata": {
        "id": "V_-nbQxkJ5lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Submit your best three models to the leader board for the SST Model Share competition."
      ],
      "metadata": {
        "id": "3uu8NRj0z1As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After you submit your first three models, describe your best model with your team via your team slack channel "
      ],
      "metadata": {
        "id": "I0NWOLI4ztfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit and submit up to three more models after learning from your team."
      ],
      "metadata": {
        "id": "W6eemSdmz9El"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Transfer learning with CNN"
      ],
      "metadata": {
        "id": "Oq9YvN-SJ8No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model4.add(layers.Conv1D(16, 6, activation='relu')) \n",
        "model4.add(layers.Conv1D(16, 6, activation='relu')) \n",
        "model4.add(layers.Conv1D(16, 3, activation='relu')) \n",
        "model4.add(layers.Conv1D(16, 3, activation='relu')) \n",
        "model4.add(layers.GlobalMaxPooling1D())\n",
        "model4.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "jVXOB9Yh0MU5"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.layers[0].set_weights([embedding_matrix])\n",
        "model4.layers[0].trainable = False\n",
        "\n",
        "model4.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model4.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n",
        "model4.save_weights('pre_trained_glove_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2tNmFN3J__1",
        "outputId": "96039e8b-61da-4ed0-f5a0-cfaa6f7d4d30"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 4s 16ms/step - loss: 0.6331 - acc: 0.6371 - val_loss: 0.8716 - val_acc: 0.3613\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 2s 14ms/step - loss: 0.5581 - acc: 0.7029 - val_loss: 0.9604 - val_acc: 0.4436\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 3s 15ms/step - loss: 0.5224 - acc: 0.7365 - val_loss: 0.5930 - val_acc: 0.7290\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 2s 13ms/step - loss: 0.4949 - acc: 0.7509 - val_loss: 0.6509 - val_acc: 0.6929\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.4706 - acc: 0.7751 - val_loss: 0.6186 - val_acc: 0.7175\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 3s 15ms/step - loss: 0.4440 - acc: 0.7861 - val_loss: 1.0402 - val_acc: 0.4574\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 3s 19ms/step - loss: 0.4142 - acc: 0.8094 - val_loss: 0.5731 - val_acc: 0.7399\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 4s 21ms/step - loss: 0.3890 - acc: 0.8201 - val_loss: 0.6100 - val_acc: 0.7211\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 2s 14ms/step - loss: 0.3545 - acc: 0.8419 - val_loss: 0.4942 - val_acc: 0.7818\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 2s 13ms/step - loss: 0.3232 - acc: 0.8568 - val_loss: 0.9146 - val_acc: 0.6293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model4 = model_to_onnx(model4, framework='keras',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=True,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model4.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model3.SerializeToString())"
      ],
      "metadata": {
        "id": "4M5a8YPJLD6u"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 4: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 1)\n",
        "prediction_column_index = model4.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 4 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model4.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 custom_metadata = {\"team\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcj214BILD38",
        "outputId": "1bbde523-1e54-4430-8b1c-acd2faade2f9"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 5ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 275\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "YsWtU9bALD1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Transfer learning with SLTM"
      ],
      "metadata": {
        "id": "k5yVd49DKA7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model5.add(LSTM(32, return_sequences=True))\n",
        "model5.add(LSTM(32, return_sequences=True))\n",
        "model5.add(LSTM(32, return_sequences=True))\n",
        "model5.add(LSTM(32))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(32, activation='softmax'))\n",
        "model5.add(Dense(16, activation='softmax'))\n",
        "model5.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "U-KCR3FbKDBk"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.layers[0].set_weights([embedding_matrix])\n",
        "model5.layers[0].trainable = False\n",
        "\n",
        "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model5.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwJoSHINKC3g",
        "outputId": "6f561632-c680-474b-8a82-423adb324c68"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 23s 78ms/step - loss: 0.6757 - acc: 0.6149 - val_loss: 0.8189 - val_acc: 0.1488\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 13s 73ms/step - loss: 0.6677 - acc: 0.6149 - val_loss: 0.8568 - val_acc: 0.1488\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 15s 87ms/step - loss: 0.6668 - acc: 0.6149 - val_loss: 0.8765 - val_acc: 0.1488\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 22s 128ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8843 - val_acc: 0.1488\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 13s 76ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8798 - val_acc: 0.1488\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 15s 89ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8829 - val_acc: 0.1488\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 14s 80ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8820 - val_acc: 0.1488\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 14s 79ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8851 - val_acc: 0.1488\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 11s 64ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8851 - val_acc: 0.1488\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 14s 80ms/step - loss: 0.6666 - acc: 0.6149 - val_loss: 0.8826 - val_acc: 0.1488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model5 = model_to_onnx(model5, framework='keras',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model5.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model5.SerializeToString())"
      ],
      "metadata": {
        "id": "BvoWAUJtLKCZ"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 5: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 1)\n",
        "prediction_column_index = model5.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 5 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model5.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 custom_metadata = {\"team\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NhLQmZDLJ_y",
        "outputId": "c9398ecb-f83e-44b7-9eea-48f13fb47a9d"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 4s 29ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 278\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "UAR8FhrlLJ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Transfer learning with CNN, using Keras Tuner"
      ],
      "metadata": {
        "id": "N9VKZXhiKDbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hacBS6LLgtRW",
        "outputId": "daebc3ef-8b83-45e0-8a9e-ad605a65f006"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.3.5 kt-legacy-1.0.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "\n",
        "#Define model structure & parameter search space with function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Embedding(10000, 100, input_length=40))\n",
        "    model.add(layers.Conv1D(filters=hp.Int(\"filters\", min_value=8, max_value=32, step=4), kernel_size=3, strides=3))\n",
        "    model.add(layers.Conv1D(filters=hp.Int(\"filters\", min_value=8, max_value=32, step=4), kernel_size=3, strides=3))\n",
        "    model.add(layers.Conv1D(filters=hp.Int(\"filters\", min_value=8, max_value=32, step=4), kernel_size=3, strides=3))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "#initialize the tuner (which will search through parameters)\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model, \n",
        "    objective=\"val_accuracy\", # objective to optimize\n",
        "    max_trials=3, #max number of trials to run during search\n",
        "    executions_per_trial=1, #higher number reduces variance of results; guages model performance more accurately \n",
        "    overwrite=True,\n",
        "    directory=\"tuning_model\",\n",
        "    project_name=\"tuning_units\",\n",
        ")\n",
        "\n",
        "tuner.search(preprocessor(X_train), y_train, epochs=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFeaqpxWfSye",
        "outputId": "393feab1-54b5-40fc-bb51-7fcb269ccdf7"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_accuracy: 0.1488439291715622\n",
            "\n",
            "Best val_accuracy So Far: 0.1488439291715622\n",
            "Total elapsed time: 00h 00m 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with best hyperparameters\n",
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "tuned_model = build_model(best_hps[0])"
      ],
      "metadata": {
        "id": "sl7YHsvYhw-r"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_model.layers[0].set_weights([embedding_matrix])\n",
        "tuned_model.layers[0].trainable = False\n",
        "\n",
        "tuned_model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = tuned_model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n",
        "tuned_model.save_weights('pre_trained_glove_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZX3uGNDKFcW",
        "outputId": "3f073d3f-18c5-4169-e0fb-13ca234c8d3a"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 2s 6ms/step - loss: 0.6672 - acc: 0.6102 - val_loss: 0.9356 - val_acc: 0.1655\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.6410 - acc: 0.6295 - val_loss: 0.8749 - val_acc: 0.2478\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.6251 - acc: 0.6454 - val_loss: 0.8897 - val_acc: 0.2847\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 1s 7ms/step - loss: 0.6116 - acc: 0.6570 - val_loss: 0.8641 - val_acc: 0.3049\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 1s 7ms/step - loss: 0.6022 - acc: 0.6660 - val_loss: 0.7972 - val_acc: 0.3642\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.5921 - acc: 0.6729 - val_loss: 0.8043 - val_acc: 0.3822\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 1s 7ms/step - loss: 0.5847 - acc: 0.6801 - val_loss: 0.8396 - val_acc: 0.3519\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.5777 - acc: 0.6830 - val_loss: 0.8699 - val_acc: 0.3302\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.5682 - acc: 0.6908 - val_loss: 1.0110 - val_acc: 0.2890\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.5635 - acc: 0.6962 - val_loss: 0.9052 - val_acc: 0.3223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model6 = model_to_onnx(tuned_model, framework='keras',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=True,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model6.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model6.SerializeToString())"
      ],
      "metadata": {
        "id": "IR7NHuxDLKuY"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 6: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 1)\n",
        "prediction_column_index = tuned_model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 6 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model6.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 custom_metadata = {\"team\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tsg7RxtLKsT",
        "outputId": "efd309d5-8404-4f3c-ba82-9362069dd5f5"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 2ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 279\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "ouqL2CuVLKm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discuss results"
      ],
      "metadata": {
        "id": "_GXQnYxGz9Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Conv1D models)\n",
        "I tried keras_tune to find the best value for the number of filters, but this attempt yielded a poor result. I also decreased the number of filters and reduced the kernel size, while adding more Conv1D layers, but it did not perform well.\n",
        "\n",
        "<br/>\n",
        "(LSTM models)\n",
        "Adding multiple Dense layers deteriorated the performance of the model."
      ],
      "metadata": {
        "id": "lW_QQRKfKGqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discuss which models you tried and which models performed better and point out relevant hyper-parameter values for successful models."
      ],
      "metadata": {
        "id": "x8PKdaPYz8_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried six models in total.\n",
        "\n",
        "*   Embedding layer and four LSTM layers and one Dense layer, no dropout, 10 epochs --- accuracy = 80.02%\n",
        "*   Embedding layer and two Conv1d layers + MaxPooling + two Conv1d layers + GlobalAveragePooling --- accuracy = 75.74%\n",
        "*   Transfer learning with glove embeddings on the second model --- accuracy = 77.61%\n",
        "*   Transfer learning with glove embeddings, four Conv1D with 16 filters and kernel size of 3 --- accuracy = 73.22%\n",
        "*   Transfer learning with glove embeddings, added two Dense layers --- accuracy = 49.95%\n",
        "*   Transfer learning with glove embeddings, used Keras_tune --- accuracy = 50.60%\n",
        "\n",
        "<br/>\n",
        "The most successful model was Embedding layer and four LSTM layers and one Dense layer, no dropout, 10 epochs. Inserting glove embeddings did not necessarily improve the results. Changing from MaxPooling to AveragePooling improved the accuracy."
      ],
      "metadata": {
        "id": "dtkQVlYiKH_U"
      }
    }
  ]
}